{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ЗАДАНИЕ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def fourier_transform(img_path, out_path, out2_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    b, g, r = cv2.split(img)\n",
    "    b_f = np.fft.fft2(b)\n",
    "    g_f = np.fft.fft2(g)\n",
    "    r_f = np.fft.fft2(r)\n",
    "\n",
    "    b_f_shifted = np.fft.fftshift(b_f)\n",
    "    g_f_shifted = np.fft.fftshift(g_f)\n",
    "    r_f_shifted = np.fft.fftshift(r_f)\n",
    "\n",
    "    cv2.imwrite(out_path, np.stack([\n",
    "        np.uint8(np.abs(b_f_shifted)),\n",
    "        np.uint8(np.abs(g_f_shifted)),\n",
    "        np.uint8(np.abs(r_f_shifted))\n",
    "        ], axis=2))\n",
    "\n",
    "    h, w = b_f.shape\n",
    "    b_f[0:h//2, :] = 0\n",
    "    g_f[0:h//2, :] = 0\n",
    "    r_f[0:h//2, :] = 0\n",
    "    b_f[:, 0:w//2] = 0\n",
    "    g_f[:, 0:w//2] = 0\n",
    "    r_f[:, 0:w//2] = 0\n",
    "\n",
    "\n",
    "    b_inv = np.fft.ifft2(b_f)\n",
    "    g_inv = np.fft.ifft2(g_f)\n",
    "    r_inv = np.fft.ifft2(r_f)\n",
    "    img_inv = np.stack([\n",
    "        np.uint8(np.abs(b_inv)),\n",
    "        np.uint8(np.abs(g_inv)),\n",
    "        np.uint8(np.abs(r_inv))\n",
    "    ], axis=2)\n",
    "    cv2.imwrite(out2_path, img_inv)\n",
    "\n",
    "fourier_transform(\"im1.jpg\", \"out.jpg\", \"out2.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](im1.jpg)\n",
    "![alt text](out.jpg)![alt text](out2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ЗАДАНИЕ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io.wavfile as wav\n",
    "import numpy as np\n",
    "\n",
    "def add_noise(data):\n",
    "    noise = np.random.normal(0, 5000, data.shape)\n",
    "    noisy = data + noise.astype(data.dtype)\n",
    "    return noisy\n",
    "\n",
    "def cut_freq(data, rate, cut):\n",
    "    fft = np.fft.rfft(data, axis=0)\n",
    "    freqs = np.fft.rfftfreq(data.shape[0], 1.0/rate)\n",
    "    cut_idx = (np.abs(freqs - cut)).argmin()\n",
    "    fft[cut_idx:, :] = 0\n",
    "    filtered = np.fft.irfft(fft, axis=0).astype(data.dtype)\n",
    "    return filtered\n",
    "\n",
    "rate, data = wav.read(\"in10.wav\")\n",
    "\n",
    "noisy_data = add_noise(data)\n",
    "wav.write(\"out1.wav\", rate, noisy_data)\n",
    "\n",
    "cut_data = cut_freq(noisy_data, rate, 1000)\n",
    "wav.write(\"out2.wav\", rate, cut_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1 \n",
    "<audio controls src=\"in10.wav\" title=\"Title\"></audio>\n",
    "#2 \n",
    "<audio controls src=\"out1.wav\" title=\"Title\"></audio>\n",
    "#3 \n",
    "<audio controls src=\"out2.wav\" title=\"Title\"></audio>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
